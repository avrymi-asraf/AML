{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNvXUoIBi2RVIKFh1crwpqx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avrymi-asraf/AML/blob/main/Ex1/AML_ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils import data\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "from typing import Tuple\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "TJhiFi7cYw1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools and Calsses"
      ],
      "metadata": {
        "id": "sKsOsGldsNwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Tools code\n",
        "\n",
        "class DataSetWithIndices(data.Dataset):\n",
        "    def __init__(self,dataset):\n",
        "        self.dataset = dataset\n",
        "    def __getitem__(self, index):\n",
        "        data, target = self.dataset[index]\n",
        "        return data, target, index\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "def import_MNIST_dataset(with_index=False,batch_size=64,test=True,amount=None):\n",
        "    \"\"\"\n",
        "    Downloads the MNIST dataset and loads it into DataLoader objects for training and testing.\n",
        "\n",
        "    The MNIST dataset consists of 60,000 training images and 10,000 testing images of handwritten digits.\n",
        "    The images are normalized to have pixel values between -1 and 1.\n",
        "\n",
        "    :return: A tuple containing the training DataLoader and the testing DataLoader.\n",
        "    \"\"\"\n",
        "    # Define a transform to normalize the data\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        "    )\n",
        "\n",
        "    # Download and load the training dataset\n",
        "    trainset = torchvision.datasets.MNIST(\n",
        "        root=\"./data\", train=True, download=True, transform=transform\n",
        "    )\n",
        "    if amount:\n",
        "        subset_indices = list(range(amount))\n",
        "        trainset = data.Subset(trainset, subset_indices)\n",
        "    if with_index:\n",
        "        trainset = DataSetWithIndices(trainset)\n",
        "\n",
        "    train_loader = data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    if not test:\n",
        "        return train_loader\n",
        "\n",
        "    # Download and load the testing dataset\n",
        "    testset = torchvision.datasets.MNIST(\n",
        "        root=\"./data\", train=False, download=True, transform=transform\n",
        "    )\n",
        "    test_loader = data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "\n",
        "def import_MNIST_examples(mnist:data.DataLoader,with_index=False):\n",
        "    re = torch.empty(10,28,28)\n",
        "    indices = torch.empty(10,dtype=torch.long)\n",
        "    for i in range(10):\n",
        "        run_ind = 0\n",
        "        while(mnist.dataset[run_ind][1]!=i):\n",
        "            run_ind+=1\n",
        "        re[i]=mnist.dataset[run_ind][0]\n",
        "        indices[i] = run_ind\n",
        "    if not with_index:\n",
        "        return re.unsqueeze(1)\n",
        "    return re.unsqueeze(1), indices\n",
        "\n",
        "\n",
        "\n",
        "def import_set_examples():\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        "    )\n",
        "\n",
        "    # Download and load the training dataset\n",
        "    train_set = torchvision.datasets.MNIST(\n",
        "        root=\"./data\", train=True, download=True, transform=transform\n",
        "    )\n",
        "    test_set = torchvision.datasets.MNIST(\n",
        "        root=\"./data\",train=False,download=True,transform=transform\n",
        "    )\n",
        "    re_test = torch.empty(10,5,1,28,28) #num,examples,channels,h,w\n",
        "    re_train = torch.empty(10,5,1,28,28) #num,examples,channels,h,w\n",
        "    for num in range(10):\n",
        "        for i in range(5):\n",
        "            ind = random.randint(0,len(train_set)-1)\n",
        "            while(train_set[ind][1]!=num):\n",
        "                ind = random.randint(0,len(train_set)-1)\n",
        "            re_test[num][i] = train_set[ind][0]\n",
        "\n",
        "            ind = random.randint(0,len(test_set)-1)\n",
        "            while(test_set[ind][1]!=num):\n",
        "                ind = random.randint(0,len(test_set)-1)\n",
        "            re_train[num][i] = test_set[ind][0]\n",
        "\n",
        "    return re_test, re_train\n",
        "\n",
        "\n",
        "def train_model(model:nn.Module,data_loader,epochs=30,lr=1e-3,device='cpu'):\n",
        "    optimazer = optim.Adam(model.parameters(),lr=lr)\n",
        "    loss_func = vae_loss\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for x, _ in data_loader:\n",
        "            x = x.to(device)\n",
        "            recon_x, mu, logvar = model(x)\n",
        "            loss = loss_func(recon_x, x, mu, logvar)\n",
        "            loss.backward()\n",
        "            optimazer.step()\n",
        "            optimazer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "def min_max_normailze(x):\n",
        "    return (x - x.min()) / (x.max() - x.min())"
      ],
      "metadata": {
        "id": "RYR7VnVpea8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fBvltODeMqH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title ConvVAEamortized model\n",
        "\n",
        "\n",
        "class ConvVAEamortized(nn.Module):\n",
        "    def __init__(self, latent_dim: int = 200):\n",
        "        \"\"\"\n",
        "        Initialize the ConvVAEamortized model.\n",
        "\n",
        "        Args:\n",
        "            latent_dim (int): Dimension of the latent space. Default is 200.\n",
        "        \"\"\"\n",
        "        super(ConvVAEamortized, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                1, 32, kernel_size=3, stride=2, padding=1\n",
        "            ),  # (batch_size, 32, 14, 14)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                32, 64, kernel_size=3, stride=2, padding=1\n",
        "            ),  # (batch_size, 64, 7, 7)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                64, 128, kernel_size=3, stride=2, padding=1\n",
        "            ),  # (batch_size, 128, 4, 4)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=2),  # (batch_size, 512, 1, 1)\n",
        "        )\n",
        "\n",
        "        # Latent space\n",
        "        self.fc_mu = nn.Linear(128, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(128, latent_dim)\n",
        "        self.fc_decode = nn.Linear(latent_dim, 128)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 128, kernel_size=2),  # (batch_size, 128, 2, 2)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(\n",
        "                128, 128, kernel_size=3, stride=2, padding=1, output_padding=1\n",
        "            ),  # (batch_size, 128, 4, 4)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(\n",
        "                128, 64, kernel_size=3, stride=2, padding=1\n",
        "            ),  # (batch_size, 64, 7, 7)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(\n",
        "                64, 32, kernel_size=3, stride=2, padding=1, output_padding=1\n",
        "            ),  # (batch_size, 32, 14, 14)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(\n",
        "                32, 1, kernel_size=3, stride=2, padding=1, output_padding=1\n",
        "            ),  # (batch_size, 1, 28, 28)\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Perform the reparameterization trick.\n",
        "\n",
        "        Args:\n",
        "            mu (torch.Tensor): Mean of the latent Gaussian. Shape: (batch_size, latent_dim)\n",
        "            logvar (torch.Tensor): Log variance of the latent Gaussian. Shape: (batch_size, latent_dim)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Sampled latent vector. Shape: (batch_size, latent_dim)\n",
        "        \"\"\"\n",
        "        device = next(self.parameters()).device\n",
        "        var = torch.exp(logvar * 0.5)\n",
        "        return torch.randn_like(mu).to(device) * var + mu\n",
        "\n",
        "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Encode the input image into the latent space.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input image. Shape: (batch_size, 1, 28, 28)\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]: Mean and log variance of the latent Gaussian.\n",
        "                                               Each shape: (batch_size, latent_dim)\n",
        "        \"\"\"\n",
        "        x = self.encoder(x)\n",
        "        # add average pooling\n",
        "        x = F.adaptive_avg_pool2d(x, 1)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        mu = self.fc_mu(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        return mu, logvar\n",
        "\n",
        "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Decode the latent vector into an image.\n",
        "\n",
        "        Args:\n",
        "            z (torch.Tensor): Latent vector. Shape: (batch_size, latent_dim)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Reconstructed image. Shape: (batch_size, 1, 28, 28)\n",
        "        \"\"\"\n",
        "        z = self.fc_decode(z)\n",
        "        z = z.view(z.size(0), 128, 1, 1)\n",
        "        z = self.decoder(z)\n",
        "        return z\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass through the VAE.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input image. Shape: (batch_size, 1, 28, 28)\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: Reconstructed image, mean, and log variance.\n",
        "                                                             Shapes: (batch_size, 1, 28, 28), (batch_size, latent_dim), (batch_size, latent_dim)\n",
        "        \"\"\"\n",
        "\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon_x = self.decode(z)\n",
        "        return recon_x, mu, logvar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ConvVAElo model\n",
        "\n",
        "\n",
        "class ConvVAElo(nn.Module):\n",
        "    def __init__(self, num_train_examples: int, latent_dim: int = 200):\n",
        "        \"\"\"\n",
        "        Initialize the ConvVAElo model.\n",
        "\n",
        "        Args:\n",
        "            num_train_examples (int): Number of training examples.\n",
        "            latent_dim (int): Dimension of the latent space. Default is 200.\n",
        "        \"\"\"\n",
        "        super(ConvVAElo, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.mus = nn.Parameter(torch.randn(num_train_examples,latent_dim,requires_grad=True))\n",
        "        self.logvars =nn.Parameter(torch.randn(num_train_examples,latent_dim,requires_grad=True))\n",
        "\n",
        "        # Latent space\n",
        "        self.fc_decode = nn.Linear(latent_dim, 128)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 128, kernel_size=2),  # (batch_size, 128, 2, 2)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(\n",
        "                128, 128, kernel_size=3, stride=2, padding=1, output_padding=1\n",
        "            ),  # (batch_size, 128, 4, 4)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(\n",
        "                128, 64, kernel_size=3, stride=2, padding=1\n",
        "            ),  # (batch_size, 64, 7, 7)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(\n",
        "                64, 32, kernel_size=3, stride=2, padding=1, output_padding=1\n",
        "            ),  # (batch_size, 32, 14, 14)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(\n",
        "                32, 1, kernel_size=3, stride=2, padding=1, output_padding=1\n",
        "            ),  # (batch_size, 1, 28, 28)\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Perform the reparameterization trick.\n",
        "\n",
        "        Args:\n",
        "            mu (torch.Tensor): Mean of the latent Gaussian. Shape: (batch_size, latent_dim)\n",
        "            logvar (torch.Tensor): Log variance of the latent Gaussian. Shape: (batch_size, latent_dim)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Sampled latent vector. Shape: (batch_size, latent_dim)\n",
        "        \"\"\"\n",
        "        device = next(self.parameters()).device\n",
        "        var = torch.exp(logvar * 0.5)\n",
        "        return torch.randn_like(mu).to(device) * var + mu\n",
        "\n",
        "\n",
        "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Decode the latent vector into an image.\n",
        "\n",
        "        Args:\n",
        "            z (torch.Tensor): Latent vector. Shape: (batch_size, latent_dim)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Reconstructed image. Shape: (batch_size, 1, 28, 28)\n",
        "        \"\"\"\n",
        "        z = self.fc_decode(z)\n",
        "        z = z.view(z.size(0), 128, 1, 1)\n",
        "        z = self.decoder(z)\n",
        "        return z\n",
        "\n",
        "    def forward(self, x: torch.Tensor, indices: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass through the VAE.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input image. Shape: (batch_size, 1, 28, 28)\n",
        "            indices (torch.Tensor): Indices of the input images. Shape: (batch_size,)\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: Reconstructed image, mean, and log variance.\n",
        "                                                             Shapes: (batch_size, 1, 28, 28), (batch_size, latent_dim), (batch_size, latent_dim)\n",
        "        \"\"\"\n",
        "        mu = self.mus[indices]\n",
        "        logvar = self.logvars[indices]\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon_x = self.decode(z)\n",
        "        return recon_x, mu, logvar"
      ],
      "metadata": {
        "cellView": "form",
        "id": "73KVmYwTJh3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Loss functions\n",
        "def vae_loss(input, target, mu, logvar):\n",
        "    input, target = input.reshape(input.size(0), -1), target.reshape(target.size(0), -1)\n",
        "    std = torch.sqrt(torch.exp(logvar))\n",
        "    kld = torch.mean(mu.pow(2) + std.pow(2) - torch.log(std) - 1,dim=1)\n",
        "    return torch.mean(F.mse_loss(input, target) + kld)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DeCSfkiriBT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1: Amortized VAE.\n",
        "Train an amortized VAE on your MNIST subset, for 30 epochs. Plot the loss values after each epoch. Additionally, choose 10 random validation images (one from each class) and plot them and their reconstructions at epochs 1, 5, 10, 20 and 30. Do the same for 10 random images from the training set. Did the\n",
        "Auto-Encoder overfit the training data? Explain.\n"
      ],
      "metadata": {
        "id": "ujjfKsmeAZ3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = import_MNIST_dataset(test=False,amount=20000)\n",
        "examples = import_MNIST_examples(data_loader).to(device)"
      ],
      "metadata": {
        "id": "dsdifIaAEUwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "lr = 1e-3"
      ],
      "metadata": {
        "id": "N8wZhTLmFGb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvVAEamortized().to(device)\n",
        "optimazer = optim.Adam(model.parameters(),lr=lr)"
      ],
      "metadata": {
        "id": "qhzY7NeFEX_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title run Q1 & Q2\n",
        "\n",
        "record_data_ma = pd.DataFrame({\"epoch_loss\": None}, index=range(epochs))\n",
        "reconstruct_images_ma = {\"pre_train\": model(examples)[0].detach().cpu(),\"source\":examples.detach().cpu()}\n",
        "prior_dist_examples_ma = {}\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    loss_epoch = 0.0\n",
        "    for x, _ in tqdm(data_loader):\n",
        "\n",
        "        x = x.to(device)\n",
        "        recon_x, mu, logvar = model(x)\n",
        "        loss = vae_loss(recon_x, x, mu, logvar)\n",
        "\n",
        "        loss.backward()\n",
        "        optimazer.step()\n",
        "        optimazer.zero_grad()\n",
        "\n",
        "        loss_epoch += loss.item()\n",
        "        record_data_ma.iloc[epoch] = [loss_epoch]\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    px.line(record_data_ma).show()\n",
        "    if (epoch+1) % 5 == 0 or epoch==0:\n",
        "        model.eval()\n",
        "        letant_examples = torch.randn(10,200).to(device)\n",
        "        prior_dist_examples_ma[epoch+1] = model.decode(letant_examples).detach().cpu()\n",
        "        px.imshow(prior_dist_examples_ma[epoch+1].squeeze(1),facet_col=0).show()\n",
        "\n",
        "        reconstruct_images_ma[epoch+1] = model(examples)[0].detach().cpu()\n",
        "        px.imshow(reconstruct_images_ma[epoch+1].squeeze(1),facet_col=0).show()\n",
        "    print(f\"epoch {epoch+1}, loss: {loss_epoch:.5f}\")\n",
        "torch.save(model.state_dict(),\"ConvVAEamortized.pth\")\n",
        "clear_output(wait=True)"
      ],
      "metadata": {
        "id": "kFNegElWegT2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show examples { run: \"auto\", display-mode: \"form\"}\n",
        "reconstruct_images_ma[0] = reconstruct_images_ma[1] # only for indexes\n",
        "epoch = 30 # @param {type:\"slider\", min:0, max:30, step:5}\n",
        "px.imshow(reconstruct_images_ma[\"source\"].squeeze(1),facet_col=0).show()\n",
        "px.imshow(reconstruct_images_ma[epoch].squeeze(1),facet_col=0).show()"
      ],
      "metadata": {
        "id": "_FrWw7p37bXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n",
        "\n",
        "## האם יש overfit באימון של VAE?\n",
        "קשה לנסח\n",
        "overfit\n",
        "ברשת יוצרת.\n",
        "המשמעות היחידה יכולה להיות, שהדוגמאות יהיו מתוך סט מצומצם של דוגמאות\n",
        "(כאלה שהמודל רואה באימון)\n",
        "ותהליך היצירה לא ישקף את התמונות האמיתיות."
      ],
      "metadata": {
        "id": "SpBBFja5AslO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Q2: Sampling from a VAE.\n",
        "Sample 10 latent variables from your prior distribution, pass them in the generators\n",
        "from epochs 1, 5, 10, 20 and 30. Plot the generations from each epoch, and observe how the generator changed\n",
        "over-time (No explanation needed)."
      ],
      "metadata": {
        "id": "QxrkHbWQsf4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show examples { run: \"auto\", display-mode: \"form\"}\n",
        "prior_dist_examples_ma[0] = prior_dist_examples_ma[1] # only for indexes\n",
        "epoch = 30 # @param {type:\"slider\", min:0, max:30, step:5}\n",
        "px.imshow(prior_dist_examples_ma[epoch].squeeze(1),facet_col=0).show()"
      ],
      "metadata": {
        "id": "Ds-jzl8R9XsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Q3: Latent Optimization.\n",
        "Train a generator by Variational Inference, using Latent Optimization for optimizing the q vectors instead of a shared encoder. Initialize the q vectors by sampling from a gaussian distribution of\n",
        "q ∼ N (0, I). This will be our prior distribution for this experiment. Use the same dimensions for q as in Q1 and\n",
        "Q2."
      ],
      "metadata": {
        "id": "l4MPUiKdKrWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_set_size = 20000\n",
        "data_loader_with_indices = import_MNIST_dataset(with_index=True,test=False,amount=data_set_size)\n",
        "examples = import_MNIST_examples(data_loader_with_indices,with_index=True)"
      ],
      "metadata": {
        "id": "6oooOWdckdrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "lr = 1e-3"
      ],
      "metadata": {
        "id": "Aq54TpsOkdrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvVAElo(data_set_size).to(device)\n",
        "# chatgpt help me :)\n",
        "optimazer = optim.Adam([\n",
        "    {'params': model.mus, 'lr': 0.01},\n",
        "    {'params': model.logvars, 'lr': 0.01},\n",
        "    {'params': model.fc_decode.parameters()},\n",
        "    {'params': model.decoder.parameters()}\n",
        "], lr=0.0001)"
      ],
      "metadata": {
        "id": "WKpi-j0Qkdrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title run Q3\n",
        "\n",
        "record_data_lo = pd.DataFrame({\"epoch_loss\": None}, index=range(epochs))\n",
        "reconstruct_images_lo = {\"pre_train\": model(*examples)[0].detach().cpu(),\"source\":examples[0].detach().cpu()}\n",
        "prior_dist_examples_lo = {}\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    loss_epoch = 0.0\n",
        "    for x, _,indices in tqdm(data_loader_with_indices):\n",
        "\n",
        "        x ,indices= x.to(device),indices.to(device)\n",
        "        recon_x, mu, logvar = model(x,indices)\n",
        "        loss = vae_loss(recon_x, x, mu, logvar)\n",
        "\n",
        "        loss.backward()\n",
        "        optimazer.step()\n",
        "        optimazer.zero_grad()\n",
        "\n",
        "        loss_epoch += loss.item()\n",
        "        record_data_ma.iloc[epoch] = [loss_epoch]\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    px.line(record_data_ma).show()\n",
        "    if (epoch+1) % 5 == 0 or epoch==0:\n",
        "        model.eval()\n",
        "        letant_examples = torch.randn(10,200).to(device)\n",
        "        prior_dist_examples_lo[epoch+1] = model.decode(letant_examples).detach().cpu()\n",
        "        px.imshow(prior_dist_examples_lo[epoch+1].squeeze(1),facet_col=0).show()\n",
        "\n",
        "        reconstruct_images_lo[epoch+1] = model(*examples)[0].detach().cpu()\n",
        "        px.imshow(reconstruct_images_lo[epoch+1].squeeze(1),facet_col=0).show()\n",
        "    print(f\"epoch {epoch+1}, loss: {loss_epoch:.5f}\")\n"
      ],
      "metadata": {
        "id": "qWsPKR7vmneW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (a)\n",
        "Plot the reconstructions of 10 images (one from each class) from the training set, at epochs 1, 5, 10, 20 and 30.\n",
        "Compare these reconstructions to the ones from Q1. Which method proposed better q vectors? Explain."
      ],
      "metadata": {
        "id": "EY9Zh2-cr2yG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show examples { run: \"auto\", display-mode: \"form\"}\n",
        "epoch = 30 # @param {type:\"slider\", min:0, max:30, step:5}\n",
        "reconstruct_images_lo[0] = reconstruct_images_lo[1] # only for indexes\n",
        "px.imshow(reconstruct_images_lo[\"source\"].squeeze(1),facet_col=0).show()\n",
        "px.imshow(reconstruct_images_lo[epoch].squeeze(1),facet_col=0).show()"
      ],
      "metadata": {
        "id": "yevxVhsACAJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (b)\n",
        "Sample from your new model, by inputting it 10 latent vectors sampled from the prior distribution. Compare\n",
        "these to the samples from Q2. Was our initialization sufficient to establish a good prior distribution for this\n",
        "problem? Explain."
      ],
      "metadata": {
        "id": "Kh7mg4fcr_jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show examples { run: \"auto\", display-mode: \"form\"}\n",
        "prior_dist_examples_lo[0] = prior_dist_examples_lo[1] # only for indexes\n",
        "epoch = 0 # @param {type:\"slider\", min:0, max:30, step:5}\n",
        "px.imshow(prior_dist_examples_ma[epoch].squeeze(1),facet_col=0).show()"
      ],
      "metadata": {
        "id": "KtvsDrpBD5e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4: Computing the log-probability of an image.\n",
        "\n",
        "For each digit (0 − 9) sample 10 images: 5 images from the\n",
        "training set and 5 from the test set. Compute the log-probability of each image as described in Eq. 9.\n"
      ],
      "metadata": {
        "id": "NSNpp9fT_meP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I helpde chatGpt\n",
        "import torch\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "\n",
        "def estimate_log_probability(x, model, M=1000,sigma_p = 0.4):\n",
        "    \"\"\"\n",
        "    Estimates the log probability of an input image under the trained VAE model.\n",
        "\n",
        "    Args:\n",
        "    - x (torch.Tensor): Input image tensor of shape (1, 1, 28, 28)\n",
        "    - model (nn.Module): Trained VAE model\n",
        "    - M (int): Number of Monte Carlo samples\n",
        "\n",
        "    Returns:\n",
        "    - torch.Tensor: Estimated log probability\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    x = x.to(device)\n",
        "\n",
        "\n",
        "    mu, logvar = model.encode(x.unsqueeze(0)) #mu and var that that define the q_z\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "\n",
        "\n",
        "    x = x.flatten()\n",
        "    # distributions\n",
        "    q_z = MultivariateNormal(mu, torch.diag(std.squeeze() ** 2))\n",
        "    p_z = MultivariateNormal(torch.zeros_like(mu), torch.eye(mu.shape[1]).to(device))\n",
        "\n",
        "    # sample z\n",
        "    z = q_z.rsample((M,))\n",
        "\n",
        "    log_p_z = p_z.log_prob(z).squeeze(1)\n",
        "    log_q_z = q_z.log_prob(z).squeeze(1)\n",
        "\n",
        "    # log p(x|z)\n",
        "    x_hat = model.decode(z).view(M,-1) # the new mu for x|z\n",
        "    log_d = torch.tensor(2 * torch.pi * sigma_p ** 2).log()\n",
        "    d = x.flatten().size(0)\n",
        "    log_p_x_given_z = -0.5 * torch.sum((x - x_hat) ** 2 / (sigma_p ** 2),dim=1) \\\n",
        "                        - 0.5 * d * log_d\n",
        "\n",
        "    # Compute importance weights\n",
        "    log_w = log_p_z + log_p_x_given_z - log_q_z\n",
        "\n",
        "    # Estimate log probability using logsumexp for numerical stability\n",
        "    log_p_x = torch.logsumexp(log_w,dim=0) - torch.log(torch.tensor(M, dtype=torch.float32, device=device))\n",
        "\n",
        "    return log_p_x.item()\n",
        "probabilitis = pd.DataFrame(columns=[str(i) for i in range(10)],index=range(5))"
      ],
      "metadata": {
        "id": "0kBEgCWlNvTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_examples, train_examples = import_set_examples()\n",
        "model = ConvVAEamortized().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/ConvVAEamortized.pth\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "B56pnFpOiyNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helpde by chatGpt\n",
        "index = pd.MultiIndex.from_product([list(range(10)),[\"train\",\"test\"]],names=[\"digit\",\"data\"])\n",
        "probabilitis = pd.DataFrame(columns=[i for i in range(5)],index=index)\n",
        "for num in range(10):\n",
        "    for i in range(5):\n",
        "        probabilitis.loc[(num,\"test\"),i] = estimate_log_probability(test_examples[num][i],model)\n",
        "        probabilitis.loc[(num,\"train\"),i] = estimate_log_probability(train_examples[num][i],model)\n",
        "# probabilitis.style.format(\"{:.3f}\")"
      ],
      "metadata": {
        "id": "6dg6gi1zcrhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (a) Plot a single image from each digit, with its log-probability."
      ],
      "metadata": {
        "id": "l87i1aAAbia4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgae_list = torch.stack([train_examples[i][0] for i in range(10)])\n",
        "fig = px.imshow(imgae_list.squeeze(1),facet_col=0,color_continuous_scale='gray')\n",
        "fig.update_layout(coloraxis_showscale=False)\n",
        "fig.update_xaxes(showticklabels=False)\n",
        "fig.update_yaxes(showticklabels=False)\n",
        "for i in range(10):\n",
        "    fig.layout.annotations[i]['text'] = f'{probabilitis.loc[(i,\"test\"),0]:.3f}'\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "oxag9eJ5SBo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (b) Present the average log-probability per digit.\n",
        "Which digit is the most likely? Why do you think that is the case?"
      ],
      "metadata": {
        "id": "LRqXs0vvblPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = probabilitis.groupby(\"digit\").mean().mean(axis=1)\n",
        "min_max_normailze(mean).plot(kind=\"bar\")\n",
        "mean\n"
      ],
      "metadata": {
        "id": "PDLwC4lHwaRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (c) Present the average log-probability of the images from the (i) training set (ii) test set.\n",
        "Are images from the\n",
        "training set more or less likely? Explain your answer"
      ],
      "metadata": {
        "id": "-cdgN7UyrRIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = probabilitis.groupby(\"data\").mean().mean(axis=1)\n",
        "mean.plot(kind=\"bar\")\n",
        "mean\n"
      ],
      "metadata": {
        "id": "aDz6bTHQkuzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EiWzUbvcL_tA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}